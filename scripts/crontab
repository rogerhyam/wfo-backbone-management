# Each task to run has to be defined through a single line
# indicating with different fields when the task will be run
# and what command to run for the task
# 
# To define the time you can provide concrete values for
# minute (m), hour (h), day of month (dom), month (mon),
# and day of week (dow) or use '*' in these fields (for 'any').
# 
# Notice that tasks will be started based on the cron's system
# daemon's notion of time and timezones.
# 
# Output of the crontab jobs (including errors) is sent through
# email to the user the crontab file belongs to (unless redirected).
# 
# For example, you can run a backup of all your user accounts
# at 5 a.m every week with:
# 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/
# 
# For more information see the manual pages of crontab(5) and cron(8)
# 
# m h  dom mon dow   command

# backup live database
12 01 * * * cd /var/wfo-list/rhakhis/api/scripts && ./db_backup_live.sh && cd /var/wfo-list && ./rhakhis_db_sync_to_staging.sh > /dev/null 2>&1

# copy the last update of the code to the backup dir - so it can be picked up by the sandbox server
32 01 * * * cd /var/wfo-list && ./update_sandbox.sh > /dev/null 2>&1

# generate download files
12 02 * * * cd /var/wfo-list/rhakhis/api/scripts && php gen_identifier_match_file.php  > /dev/null 2>&1
12 03 * * 6 cd /var/wfo-list/rhakhis/api/scripts && php -d memory_limit=2048M gen_uber_dwc_file.php  > /dev/null 2>&1
02 05 * * 6 cd /var/wfo-list/rhakhis/api/scripts && php gen_uber_R_dwc_file.php  > /dev/null 2>&1
14 05 * * 6 cd /var/wfo-list/rhakhis/api/scripts && php -d memory_limit=2048M gen_ipni_to_wfo.php  > /dev/null 2>&1
32 02 * * * cd /var/wfo-list/rhakhis/api/scripts && php gen_name_match_file.php  > /dev/null 2>&1
32 04 * * * cd /var/wfo-list/rhakhis/api/scripts &&php -d memory_limit=5G gen_name_match_big_file.php > /dev/null 2>&1
56 * * * * cd /var/wfo-list/rhakhis/api/scripts && php -d memory_limit=2048M gen_family_dwc_file.php > /dev/null 2>&1
06 * * * * cd /var/wfo-list/rhakhis/api/scripts && php -d memory_limit=2048M gen_family_html_file.php > /dev/null 2>&1
52 08 * * 6 cd /var/wfo-list/rhakhis/api/scripts && php gen_integrity_reports.php > /dev/null 2>&1

# The stats run every hour but only process 1000 genera. It will only update rows over 2 days old.
22 * * * * cd /var/wfo-list/rhakhis/api/scripts && php -d memory_limit=1024M  gen_genus_stats.php '2 DAY' > /dev/null 2>&1

# Stats download files are generated every two days
10 1 */2 * * cd /var/wfo-list/rhakhis/api/scripts && php gen_stats_files.php > /dev/null 2>&1

# we scrape gbif every hour
15 * * * * cd /var/wfo-list/rhakhis/api/scripts && php gen_gbif_count.php > /dev/null 2>&1

# get the kew data each day
40 03 * * * cd /var/wfo-list/kew_sync/scripts && php daily_sync.php > /dev/null 2>&1

# check for new DOIs in IPNI on the middle of each month
40 07 15 * * cd /var/wfo-list/kew_sync/scripts && php import_ipni_doi_periodic.php 100 > /dev/null 2>&1

# truncating tables that might get too big each month
45 4 1 * * cd /var/wfo-list/kew_sync/scripts && php truncate_names_log.php > /dev/null 2>&1 
45 5 1 * * cd /var/wfo-list/kew_sync/scripts && php truncate_genus_stats_log.php > /dev/null 2>&1 
